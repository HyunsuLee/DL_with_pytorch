{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6cefc50c90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck'] # here, 0 airplane, 2 bird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path = '/home/hyunsu/Documents/data_ML/cifar10/'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label]) # make tuple\n",
    "          for img, label in cifar10 \n",
    "          if label in [0, 2]] # do if airplane or bird\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "n_out = 2\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                3072,  # 32 x 32 x 3 feature\n",
    "                512,   # <2>\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(\n",
    "                512,   # <2>\n",
    "                n_out, # <3>\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0900, 0.2447, 0.6652],\n",
       "         [0.0900, 0.2447, 0.6652]]),\n",
       " tensor([2., 2.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                  [1.0, 2.0, 3.0]]) # 2 x 3\n",
    "\n",
    "softmax(x), x.mean(dim=1) # to understand the dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, _ = cifar2[0]\n",
    "\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3072])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch = img.view(-1).unsqueeze(0)\n",
    "img_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4784, 0.5216]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(img_batch)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, index = torch.max(out, dim=1)\n",
    "\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.tensor([\n",
    "    [0.6, 0.4],\n",
    "    [0.9, 0.1],\n",
    "    [0.3, 0.7],\n",
    "    [0.2, 0.8],\n",
    "])\n",
    "class_index = torch.tensor([0, 0, 1, 1]).unsqueeze(1)\n",
    "\n",
    "truth = torch.zeros((4,2)) # one-hot encoding\n",
    "truth.scatter_(dim=1, index=class_index, value=1.0)\n",
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mse(out):\n",
    "    return ((out - truth) ** 2).sum(dim=1).mean()\n",
    "mse(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6000],\n",
       "        [0.9000],\n",
       "        [0.7000],\n",
       "        [0.8000]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.gather(dim=1, index=class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3024])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def likelihood(out):\n",
    "    prod = 1.0\n",
    "    for x in out.gather(dim=1, index=class_index):\n",
    "        prod *= x\n",
    "    return prod\n",
    "\n",
    "likelihood(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1960])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def neg_log_likelihood(out):\n",
    "    return -likelihood(out).log()\n",
    "\n",
    "neg_log_likelihood(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0750, 0.1500, 0.2500, 0.4750])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out0 = out.clone().detach()\n",
    "out0[0] = torch.tensor([0.9, 0.1]) # more right\n",
    "\n",
    "out2 = out.clone().detach()\n",
    "out2[0] = torch.tensor([0.4, 0.6]) # slightly wrong\n",
    "\n",
    "out3 = out.clone().detach()\n",
    "out3[0] = torch.tensor([0.1, 0.9]) # very wrong\n",
    "\n",
    "mse_comparison = torch.tensor([mse(o) for o in [out0, out, out2, out3]])\n",
    "mse_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-50.0000,   0.0000,  66.6667, 216.6667])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((mse_comparison / mse_comparison[1]) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7905, 1.1960, 1.6015, 2.9878])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll_comparison = torch.tensor([neg_log_likelihood(o) \n",
    "                               for o in [out0, out, out2, out3]])\n",
    "nll_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-33.9016,   0.0000,  33.9016, 149.8121])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((nll_comparison / nll_comparison[1]) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1.]]), tensor([[-104.,    0.]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[0.0, 104.0]])\n",
    "\n",
    "softmax(x), log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(softmax(x)) # the reason to use logsoftmax instead of softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-104.,    0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(log_softmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5077, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = cifar2[0]\n",
    "\n",
    "out = model(img.view(-1).unsqueeze(0))\n",
    "\n",
    "loss(out, torch.tensor([label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 6.104034\n",
      "Epoch: 1, Loss: 5.614705\n",
      "Epoch: 2, Loss: 10.030086\n",
      "Epoch: 3, Loss: 4.192981\n",
      "Epoch: 4, Loss: 3.284071\n",
      "Epoch: 5, Loss: 9.248923\n",
      "Epoch: 6, Loss: 5.384418\n",
      "Epoch: 7, Loss: 3.068453\n",
      "Epoch: 8, Loss: 11.755852\n",
      "Epoch: 9, Loss: 10.503537\n",
      "Epoch: 10, Loss: 1.813431\n",
      "Epoch: 11, Loss: 8.145979\n",
      "Epoch: 12, Loss: 7.243825\n",
      "Epoch: 13, Loss: 3.537252\n",
      "Epoch: 14, Loss: 5.244114\n",
      "Epoch: 15, Loss: 7.443619\n",
      "Epoch: 16, Loss: 4.032690\n",
      "Epoch: 17, Loss: 3.282646\n",
      "Epoch: 18, Loss: 7.826687\n",
      "Epoch: 19, Loss: 13.519883\n",
      "Epoch: 20, Loss: 8.205056\n",
      "Epoch: 21, Loss: 12.670047\n",
      "Epoch: 22, Loss: 9.744849\n",
      "Epoch: 23, Loss: 3.434032\n",
      "Epoch: 24, Loss: 11.118172\n",
      "Epoch: 25, Loss: 14.953550\n",
      "Epoch: 26, Loss: 7.084696\n",
      "Epoch: 27, Loss: 20.254307\n",
      "Epoch: 28, Loss: 13.225882\n",
      "Epoch: 29, Loss: 7.669613\n",
      "Epoch: 30, Loss: 12.838577\n",
      "Epoch: 31, Loss: 10.905982\n",
      "Epoch: 32, Loss: 18.076811\n",
      "Epoch: 33, Loss: 12.677045\n",
      "Epoch: 34, Loss: 13.437262\n",
      "Epoch: 35, Loss: 13.721916\n",
      "Epoch: 36, Loss: 10.082571\n",
      "Epoch: 37, Loss: 12.501238\n",
      "Epoch: 38, Loss: 11.160411\n",
      "Epoch: 39, Loss: 12.083444\n",
      "Epoch: 40, Loss: 10.236360\n",
      "Epoch: 41, Loss: 14.577423\n",
      "Epoch: 42, Loss: 20.007145\n",
      "Epoch: 43, Loss: 17.058136\n",
      "Epoch: 44, Loss: 12.887622\n",
      "Epoch: 45, Loss: 17.695026\n",
      "Epoch: 46, Loss: 9.147426\n",
      "Epoch: 47, Loss: 18.391493\n",
      "Epoch: 48, Loss: 8.695483\n",
      "Epoch: 49, Loss: 8.077578\n",
      "Epoch: 50, Loss: 0.903209\n",
      "Epoch: 51, Loss: 8.525837\n",
      "Epoch: 52, Loss: 17.811563\n",
      "Epoch: 53, Loss: 10.995426\n",
      "Epoch: 54, Loss: 15.079213\n",
      "Epoch: 55, Loss: 12.767770\n",
      "Epoch: 56, Loss: 16.936079\n",
      "Epoch: 57, Loss: 14.381650\n",
      "Epoch: 58, Loss: 6.747261\n",
      "Epoch: 59, Loss: 19.978603\n",
      "Epoch: 60, Loss: 12.063923\n",
      "Epoch: 61, Loss: 7.099912\n",
      "Epoch: 62, Loss: 6.812053\n",
      "Epoch: 63, Loss: 7.155506\n",
      "Epoch: 64, Loss: 3.781944\n",
      "Epoch: 65, Loss: 9.709451\n",
      "Epoch: 66, Loss: 15.692888\n",
      "Epoch: 67, Loss: 3.254898\n",
      "Epoch: 68, Loss: 3.791859\n",
      "Epoch: 69, Loss: 12.082941\n",
      "Epoch: 70, Loss: 8.411386\n",
      "Epoch: 71, Loss: 3.688842\n",
      "Epoch: 72, Loss: 8.190401\n",
      "Epoch: 73, Loss: 12.780724\n",
      "Epoch: 74, Loss: 1.593419\n",
      "Epoch: 75, Loss: 1.237834\n",
      "Epoch: 76, Loss: 6.875455\n",
      "Epoch: 77, Loss: 1.914600\n",
      "Epoch: 78, Loss: 10.313355\n",
      "Epoch: 79, Loss: 1.443441\n",
      "Epoch: 80, Loss: 0.043575\n",
      "Epoch: 81, Loss: 9.304488\n",
      "Epoch: 82, Loss: 0.286807\n",
      "Epoch: 83, Loss: 0.003478\n",
      "Epoch: 84, Loss: 6.434938\n",
      "Epoch: 85, Loss: 5.923908\n",
      "Epoch: 86, Loss: 0.038194\n",
      "Epoch: 87, Loss: 4.856761\n",
      "Epoch: 88, Loss: 10.344280\n",
      "Epoch: 89, Loss: 13.984936\n",
      "Epoch: 90, Loss: 0.391330\n",
      "Epoch: 91, Loss: 6.514770\n",
      "Epoch: 92, Loss: 0.392143\n",
      "Epoch: 93, Loss: 2.030744\n",
      "Epoch: 94, Loss: 2.107523\n",
      "Epoch: 95, Loss: 20.176796\n",
      "Epoch: 96, Loss: 3.638741\n",
      "Epoch: 97, Loss: 7.877125\n",
      "Epoch: 98, Loss: 4.838938\n",
      "Epoch: 99, Loss: 2.684534\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim=1)).to(device)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in cifar2:\n",
    "        out = model(img.view(-1).unsqueeze(0).to(device))\n",
    "        loss = loss_fn(out, torch.tensor([label]).to(device))\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.290652\n",
      "Epoch: 1, Loss: 0.596096\n",
      "Epoch: 2, Loss: 0.288824\n",
      "Epoch: 3, Loss: 0.372863\n",
      "Epoch: 4, Loss: 0.431011\n",
      "Epoch: 5, Loss: 0.509270\n",
      "Epoch: 6, Loss: 0.184279\n",
      "Epoch: 7, Loss: 0.458323\n",
      "Epoch: 8, Loss: 0.434904\n",
      "Epoch: 9, Loss: 0.281615\n",
      "Epoch: 10, Loss: 0.262083\n",
      "Epoch: 11, Loss: 0.378605\n",
      "Epoch: 12, Loss: 0.406189\n",
      "Epoch: 13, Loss: 0.323112\n",
      "Epoch: 14, Loss: 0.353314\n",
      "Epoch: 15, Loss: 0.297496\n",
      "Epoch: 16, Loss: 0.113304\n",
      "Epoch: 17, Loss: 0.233832\n",
      "Epoch: 18, Loss: 0.403771\n",
      "Epoch: 19, Loss: 0.265747\n",
      "Epoch: 20, Loss: 0.110455\n",
      "Epoch: 21, Loss: 0.148265\n",
      "Epoch: 22, Loss: 0.189928\n",
      "Epoch: 23, Loss: 0.356492\n",
      "Epoch: 24, Loss: 0.527282\n",
      "Epoch: 25, Loss: 0.309290\n",
      "Epoch: 26, Loss: 0.438987\n",
      "Epoch: 27, Loss: 0.235336\n",
      "Epoch: 28, Loss: 0.390660\n",
      "Epoch: 29, Loss: 0.052564\n",
      "Epoch: 30, Loss: 0.167443\n",
      "Epoch: 31, Loss: 0.433880\n",
      "Epoch: 32, Loss: 0.192829\n",
      "Epoch: 33, Loss: 0.094194\n",
      "Epoch: 34, Loss: 0.298321\n",
      "Epoch: 35, Loss: 0.147978\n",
      "Epoch: 36, Loss: 0.235584\n",
      "Epoch: 37, Loss: 0.175474\n",
      "Epoch: 38, Loss: 0.176204\n",
      "Epoch: 39, Loss: 0.033435\n",
      "Epoch: 40, Loss: 0.167390\n",
      "Epoch: 41, Loss: 0.129554\n",
      "Epoch: 42, Loss: 0.069714\n",
      "Epoch: 43, Loss: 0.063619\n",
      "Epoch: 44, Loss: 0.164643\n",
      "Epoch: 45, Loss: 0.097733\n",
      "Epoch: 46, Loss: 0.128092\n",
      "Epoch: 47, Loss: 0.194367\n",
      "Epoch: 48, Loss: 0.049673\n",
      "Epoch: 49, Loss: 0.098116\n",
      "Epoch: 50, Loss: 0.216069\n",
      "Epoch: 51, Loss: 0.033803\n",
      "Epoch: 52, Loss: 0.050956\n",
      "Epoch: 53, Loss: 0.036949\n",
      "Epoch: 54, Loss: 0.118608\n",
      "Epoch: 55, Loss: 0.103853\n",
      "Epoch: 56, Loss: 0.066950\n",
      "Epoch: 57, Loss: 0.025243\n",
      "Epoch: 58, Loss: 0.021103\n",
      "Epoch: 59, Loss: 0.055735\n",
      "Epoch: 60, Loss: 0.020789\n",
      "Epoch: 61, Loss: 0.059020\n",
      "Epoch: 62, Loss: 0.049005\n",
      "Epoch: 63, Loss: 0.149845\n",
      "Epoch: 64, Loss: 0.031363\n",
      "Epoch: 65, Loss: 0.042432\n",
      "Epoch: 66, Loss: 0.052077\n",
      "Epoch: 67, Loss: 0.071797\n",
      "Epoch: 68, Loss: 0.032511\n",
      "Epoch: 69, Loss: 0.048798\n",
      "Epoch: 70, Loss: 0.024265\n",
      "Epoch: 71, Loss: 0.070216\n",
      "Epoch: 72, Loss: 0.036854\n",
      "Epoch: 73, Loss: 0.056011\n",
      "Epoch: 74, Loss: 0.063296\n",
      "Epoch: 75, Loss: 0.037141\n",
      "Epoch: 76, Loss: 0.058666\n",
      "Epoch: 77, Loss: 0.022081\n",
      "Epoch: 78, Loss: 0.015367\n",
      "Epoch: 79, Loss: 0.057765\n",
      "Epoch: 80, Loss: 0.076627\n",
      "Epoch: 81, Loss: 0.016357\n",
      "Epoch: 82, Loss: 0.037213\n",
      "Epoch: 83, Loss: 0.026932\n",
      "Epoch: 84, Loss: 0.057462\n",
      "Epoch: 85, Loss: 0.017927\n",
      "Epoch: 86, Loss: 0.022115\n",
      "Epoch: 87, Loss: 0.027282\n",
      "Epoch: 88, Loss: 0.019865\n",
      "Epoch: 89, Loss: 0.024780\n",
      "Epoch: 90, Loss: 0.056465\n",
      "Epoch: 91, Loss: 0.021495\n",
      "Epoch: 92, Loss: 0.011607\n",
      "Epoch: 93, Loss: 0.025417\n",
      "Epoch: 94, Loss: 0.044146\n",
      "Epoch: 95, Loss: 0.011179\n",
      "Epoch: 96, Loss: 0.007331\n",
      "Epoch: 97, Loss: 0.025513\n",
      "Epoch: 98, Loss: 0.026687\n",
      "Epoch: 99, Loss: 0.017964\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2),\n",
    "            nn.LogSoftmax(dim=1)).to(device)\n",
    "\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1).to(device))\n",
    "        loss = loss_fn(outputs, labels.to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999500\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1).to(device))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        labels = labels.to(device)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.811500\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1).to(device))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        labels = labels.to(device)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.304551\n",
      "Epoch: 1, Loss: 0.624621\n",
      "Epoch: 2, Loss: 0.218915\n",
      "Epoch: 3, Loss: 0.393432\n",
      "Epoch: 4, Loss: 0.365717\n",
      "Epoch: 5, Loss: 0.256471\n",
      "Epoch: 6, Loss: 0.518236\n",
      "Epoch: 7, Loss: 0.544386\n",
      "Epoch: 8, Loss: 0.248678\n",
      "Epoch: 9, Loss: 0.348357\n",
      "Epoch: 10, Loss: 0.357375\n",
      "Epoch: 11, Loss: 0.342049\n",
      "Epoch: 12, Loss: 0.280576\n",
      "Epoch: 13, Loss: 0.522524\n",
      "Epoch: 14, Loss: 0.494793\n",
      "Epoch: 15, Loss: 0.357507\n",
      "Epoch: 16, Loss: 0.527270\n",
      "Epoch: 17, Loss: 0.774763\n",
      "Epoch: 18, Loss: 0.206350\n",
      "Epoch: 19, Loss: 0.396299\n",
      "Epoch: 20, Loss: 0.293799\n",
      "Epoch: 21, Loss: 0.233297\n",
      "Epoch: 22, Loss: 0.290985\n",
      "Epoch: 23, Loss: 0.268711\n",
      "Epoch: 24, Loss: 0.340262\n",
      "Epoch: 25, Loss: 0.273507\n",
      "Epoch: 26, Loss: 0.264111\n",
      "Epoch: 27, Loss: 0.285662\n",
      "Epoch: 28, Loss: 0.204051\n",
      "Epoch: 29, Loss: 0.177308\n",
      "Epoch: 30, Loss: 0.144793\n",
      "Epoch: 31, Loss: 0.094282\n",
      "Epoch: 32, Loss: 0.165821\n",
      "Epoch: 33, Loss: 0.136289\n",
      "Epoch: 34, Loss: 0.111931\n",
      "Epoch: 35, Loss: 0.070409\n",
      "Epoch: 36, Loss: 0.060739\n",
      "Epoch: 37, Loss: 0.161899\n",
      "Epoch: 38, Loss: 0.041960\n",
      "Epoch: 39, Loss: 0.222695\n",
      "Epoch: 40, Loss: 0.169895\n",
      "Epoch: 41, Loss: 0.264857\n",
      "Epoch: 42, Loss: 0.052622\n",
      "Epoch: 43, Loss: 0.228513\n",
      "Epoch: 44, Loss: 0.277979\n",
      "Epoch: 45, Loss: 0.080318\n",
      "Epoch: 46, Loss: 0.035052\n",
      "Epoch: 47, Loss: 0.063577\n",
      "Epoch: 48, Loss: 0.126355\n",
      "Epoch: 49, Loss: 0.013309\n",
      "Epoch: 50, Loss: 0.023036\n",
      "Epoch: 51, Loss: 0.156214\n",
      "Epoch: 52, Loss: 0.104808\n",
      "Epoch: 53, Loss: 0.082247\n",
      "Epoch: 54, Loss: 0.006819\n",
      "Epoch: 55, Loss: 0.244506\n",
      "Epoch: 56, Loss: 0.009142\n",
      "Epoch: 57, Loss: 0.029400\n",
      "Epoch: 58, Loss: 0.006662\n",
      "Epoch: 59, Loss: 0.017397\n",
      "Epoch: 60, Loss: 0.011368\n",
      "Epoch: 61, Loss: 0.006658\n",
      "Epoch: 62, Loss: 0.057957\n",
      "Epoch: 63, Loss: 0.016405\n",
      "Epoch: 64, Loss: 0.003269\n",
      "Epoch: 65, Loss: 0.005047\n",
      "Epoch: 66, Loss: 0.004609\n",
      "Epoch: 67, Loss: 0.003713\n",
      "Epoch: 68, Loss: 0.003734\n",
      "Epoch: 69, Loss: 0.071963\n",
      "Epoch: 70, Loss: 0.006130\n",
      "Epoch: 71, Loss: 0.007321\n",
      "Epoch: 72, Loss: 0.004358\n",
      "Epoch: 73, Loss: 0.013239\n",
      "Epoch: 74, Loss: 0.001064\n",
      "Epoch: 75, Loss: 0.000626\n",
      "Epoch: 76, Loss: 0.001169\n",
      "Epoch: 77, Loss: 0.000883\n",
      "Epoch: 78, Loss: 0.001942\n",
      "Epoch: 79, Loss: 0.002709\n",
      "Epoch: 80, Loss: 0.015782\n",
      "Epoch: 81, Loss: 0.003648\n",
      "Epoch: 82, Loss: 0.304163\n",
      "Epoch: 83, Loss: 0.000992\n",
      "Epoch: 84, Loss: 0.003172\n",
      "Epoch: 85, Loss: 0.000534\n",
      "Epoch: 86, Loss: 0.002500\n",
      "Epoch: 87, Loss: 0.001896\n",
      "Epoch: 88, Loss: 0.033590\n",
      "Epoch: 89, Loss: 0.017585\n",
      "Epoch: 90, Loss: 0.001574\n",
      "Epoch: 91, Loss: 0.004163\n",
      "Epoch: 92, Loss: 0.000359\n",
      "Epoch: 93, Loss: 0.004165\n",
      "Epoch: 94, Loss: 0.003613\n",
      "Epoch: 95, Loss: 0.001626\n",
      "Epoch: 96, Loss: 0.002169\n",
      "Epoch: 97, Loss: 0.000700\n",
      "Epoch: 98, Loss: 0.000735\n",
      "Epoch: 99, Loss: 0.000859\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2)).to(device)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1).to(device))\n",
    "        loss = loss_fn(outputs, labels.to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999800\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1).to(device))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        labels = labels.to(device)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.812000\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1).to(device))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        labels = labels.to(device)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3737474"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3737474"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters() if p.requires_grad == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1574402"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_model = nn.Sequential(\n",
    "                nn.Linear(3072, 512),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(512, 2),\n",
    "                nn.LogSoftmax(dim=1))\n",
    "\n",
    "sum([p.numel() for p in first_model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1573376"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in nn.Linear(3072, 512).parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3146752"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in nn.Linear(3072, 1024).parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 3072]), torch.Size([1024]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(3072, 1024)\n",
    "\n",
    "linear.weight.shape, linear.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 16, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 3, 3])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = cifar2[0]\n",
    "\n",
    "output = conv(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 16, 30, 30]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.permute(1, 2, 0), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 30, 30])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 32])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv.bias.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv.weight.fill_(1.0 / 9.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    conv.weight[:] = torch.tensor([[-1.0, 0.0, 1.0],\n",
    "                                   [-1.0, 0.0, 1.0],\n",
    "                                   [-1.0, 0.0, 1.0]])\n",
    "    conv.bias.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = nn.MaxPool2d(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 16, 16])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pool(img.unsqueeze(0))\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1), # 16 x 32 x 32\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2), # 16 x 16 x 16\n",
    "            nn.Conv2d(16, 8, kernel_size=3, padding=1), # 8 x 16 x 16\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2), # 8 x 8 x 8\n",
    "            # torch.flatten(),\n",
    "            nn.Linear(512, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18090"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model(img.unsqueeze(0)) # since there no flatten, you can forward this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act4 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8) # this work like flatten\n",
    "        out = self.act4(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18090"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "\n",
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2405, -0.0994]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.546526\n",
      "Epoch: 1, Loss: 0.518879\n",
      "Epoch: 2, Loss: 0.437984\n",
      "Epoch: 3, Loss: 0.403006\n",
      "Epoch: 4, Loss: 0.214272\n",
      "Epoch: 5, Loss: 0.324698\n",
      "Epoch: 6, Loss: 0.424224\n",
      "Epoch: 7, Loss: 0.163004\n",
      "Epoch: 8, Loss: 0.527817\n",
      "Epoch: 9, Loss: 0.353811\n",
      "Epoch: 10, Loss: 0.201866\n",
      "Epoch: 11, Loss: 0.460753\n",
      "Epoch: 12, Loss: 0.506434\n",
      "Epoch: 13, Loss: 0.081211\n",
      "Epoch: 14, Loss: 0.378655\n",
      "Epoch: 15, Loss: 0.343203\n",
      "Epoch: 16, Loss: 0.347149\n",
      "Epoch: 17, Loss: 0.436019\n",
      "Epoch: 18, Loss: 0.148665\n",
      "Epoch: 19, Loss: 0.405027\n",
      "Epoch: 20, Loss: 0.250077\n",
      "Epoch: 21, Loss: 0.251469\n",
      "Epoch: 22, Loss: 0.272347\n",
      "Epoch: 23, Loss: 0.114908\n",
      "Epoch: 24, Loss: 0.174334\n",
      "Epoch: 25, Loss: 0.355608\n",
      "Epoch: 26, Loss: 0.416404\n",
      "Epoch: 27, Loss: 0.108453\n",
      "Epoch: 28, Loss: 0.264927\n",
      "Epoch: 29, Loss: 0.150396\n",
      "Epoch: 30, Loss: 0.188177\n",
      "Epoch: 31, Loss: 0.136211\n",
      "Epoch: 32, Loss: 0.177020\n",
      "Epoch: 33, Loss: 0.324992\n",
      "Epoch: 34, Loss: 0.280588\n",
      "Epoch: 35, Loss: 0.060705\n",
      "Epoch: 36, Loss: 0.317196\n",
      "Epoch: 37, Loss: 0.172130\n",
      "Epoch: 38, Loss: 0.061664\n",
      "Epoch: 39, Loss: 0.141123\n",
      "Epoch: 40, Loss: 0.259475\n",
      "Epoch: 41, Loss: 0.243458\n",
      "Epoch: 42, Loss: 0.086363\n",
      "Epoch: 43, Loss: 0.081643\n",
      "Epoch: 44, Loss: 0.061343\n",
      "Epoch: 45, Loss: 0.081441\n",
      "Epoch: 46, Loss: 0.388405\n",
      "Epoch: 47, Loss: 0.312819\n",
      "Epoch: 48, Loss: 0.036489\n",
      "Epoch: 49, Loss: 0.284771\n",
      "Epoch: 50, Loss: 0.165157\n",
      "Epoch: 51, Loss: 0.185654\n",
      "Epoch: 52, Loss: 0.368947\n",
      "Epoch: 53, Loss: 0.121689\n",
      "Epoch: 54, Loss: 0.054000\n",
      "Epoch: 55, Loss: 0.132365\n",
      "Epoch: 56, Loss: 0.163337\n",
      "Epoch: 57, Loss: 0.223012\n",
      "Epoch: 58, Loss: 0.136172\n",
      "Epoch: 59, Loss: 0.261311\n",
      "Epoch: 60, Loss: 0.247160\n",
      "Epoch: 61, Loss: 0.126661\n",
      "Epoch: 62, Loss: 0.079738\n",
      "Epoch: 63, Loss: 0.150899\n",
      "Epoch: 64, Loss: 0.118944\n",
      "Epoch: 65, Loss: 0.170098\n",
      "Epoch: 66, Loss: 0.019999\n",
      "Epoch: 67, Loss: 0.399902\n",
      "Epoch: 68, Loss: 0.077241\n",
      "Epoch: 69, Loss: 0.139547\n",
      "Epoch: 70, Loss: 0.198945\n",
      "Epoch: 71, Loss: 0.227809\n",
      "Epoch: 72, Loss: 0.213918\n",
      "Epoch: 73, Loss: 0.139166\n",
      "Epoch: 74, Loss: 0.265134\n",
      "Epoch: 75, Loss: 0.150220\n",
      "Epoch: 76, Loss: 0.365808\n",
      "Epoch: 77, Loss: 0.077374\n",
      "Epoch: 78, Loss: 0.059087\n",
      "Epoch: 79, Loss: 0.073815\n",
      "Epoch: 80, Loss: 0.019726\n",
      "Epoch: 81, Loss: 0.078126\n",
      "Epoch: 82, Loss: 0.071664\n",
      "Epoch: 83, Loss: 0.114647\n",
      "Epoch: 84, Loss: 0.056777\n",
      "Epoch: 85, Loss: 0.087456\n",
      "Epoch: 86, Loss: 0.022316\n",
      "Epoch: 87, Loss: 0.124101\n",
      "Epoch: 88, Loss: 0.046753\n",
      "Epoch: 89, Loss: 0.091312\n",
      "Epoch: 90, Loss: 0.059977\n",
      "Epoch: 91, Loss: 0.260211\n",
      "Epoch: 92, Loss: 0.118265\n",
      "Epoch: 93, Loss: 0.166371\n",
      "Epoch: 94, Loss: 0.254142\n",
      "Epoch: 95, Loss: 0.072883\n",
      "Epoch: 96, Loss: 0.041046\n",
      "Epoch: 97, Loss: 0.054794\n",
      "Epoch: 98, Loss: 0.082813\n",
      "Epoch: 99, Loss: 0.007835\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = Net().to(device)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.to(device))\n",
    "        loss = loss_fn(outputs, labels.to(device))\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.950000\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.to(device))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        labels = labels.to(device)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.892500\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        outputs = model(imgs.to(device))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        labels = labels.to(device)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18090"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = Net().to(device)\n",
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x8 and 512x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/hyunsu/Documents/GitHub/DL_with_pytorch/p1ch7/2_birds_airplanes.ipynb Cell 76\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bubuntu223/home/hyunsu/Documents/GitHub/DL_with_pytorch/p1ch7/2_birds_airplanes.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bubuntu223/home/hyunsu/Documents/GitHub/DL_with_pytorch/p1ch7/2_birds_airplanes.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m             nn\u001b[39m.\u001b[39mConv2d(\u001b[39m3\u001b[39m, \u001b[39m16\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bubuntu223/home/hyunsu/Documents/GitHub/DL_with_pytorch/p1ch7/2_birds_airplanes.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m             nn\u001b[39m.\u001b[39mTanh(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bubuntu223/home/hyunsu/Documents/GitHub/DL_with_pytorch/p1ch7/2_birds_airplanes.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m             nn\u001b[39m.\u001b[39mTanh(),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bubuntu223/home/hyunsu/Documents/GitHub/DL_with_pytorch/p1ch7/2_birds_airplanes.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m             nn\u001b[39m.\u001b[39mLinear(\u001b[39m32\u001b[39m, \u001b[39m2\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bubuntu223/home/hyunsu/Documents/GitHub/DL_with_pytorch/p1ch7/2_birds_airplanes.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m model(img\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m))\n",
      "File \u001b[0;32m~/anaconda3/envs/th1p12/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/th1p12/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/th1p12/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/th1p12/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x8 and 512x32)"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Linear(8*8*8, 32), # no flatten, this code doesn't work\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 2))\n",
    "\n",
    "model(img.unsqueeze(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('th1p12')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "540ee3e445d1da392d2b8a7d647dcbc2bd268a0d669d2281aeea3f4a5da62e9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
